{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NN(nn.Module):\n",
    "#     def __init__(self, layers):\n",
    "#         super(NN, self).__init__()\n",
    "#         self.layers = layers\n",
    "#         self.u = self._make_layers()\n",
    "\n",
    "#     def _make_layers(self):\n",
    "#         layers = []\n",
    "#         for i in range(len(self.layers) - 2):\n",
    "#             layers.append(nn.Linear(self.layers[i], self.layers[i+1]))\n",
    "#             layers.append(nn.Tanh())\n",
    "#         layers.append(nn.Linear(self.layers[-2], self.layers[-1]))\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.u(x)\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 init.xavier_uniform_(m.weight)\n",
    "#                 if m.bias is not None:\n",
    "#                     init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    '''\n",
    "    input : nodes--- list\n",
    "                form [input features, hiddenlayer1, hiddenlayer2,...., outputfeatures]\n",
    "    '''\n",
    "    def __init__(self, nodes):\n",
    "        super(NN, self).__init__()\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for node in range(len(nodes)-2):\n",
    "            self.hidden_layers.append(nn.Linear(nodes[node], nodes[node+1]))\n",
    "        self.output_layer = nn.Linear(nodes[-2] , nodes[-1])\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers, bounds_1, bounds_2 ):\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        # u: T_e(1)\n",
    "        # v: T_l(1)\n",
    "        self.net = NN(layers)\n",
    "        self.net_2 = NN(layers)\n",
    "        self.net.init_weights()\n",
    "        self.net_2.init_weights()\n",
    "        \n",
    "        # for the first material, Au\n",
    "        lb_1 = bounds_1[0]\n",
    "        ub_1 = bounds_1[1]\n",
    "        self.lb_1 = lb_1\n",
    "        self.ub_1 = ub_1\n",
    "        \n",
    "        # for the second material, Cr\n",
    "        lb_2 = bounds_2[0]\n",
    "        ub_2 = bounds_2[1]\n",
    "        self.lb_2 = lb_2\n",
    "        self.ub_2 = ub_2\n",
    "        \n",
    "        \n",
    "    def forward(self, X, t, material):\n",
    "        if material==1:\n",
    "            X = 2.0 * ( X - self.lb_1[0] ) / ( self.ub_1[0] - self.lb_1[0] ) - 1.0\n",
    "            u = self.net(torch.cat([X, t], dim=1))\n",
    "            u_x = torch.autograd.grad(u, X, torch.ones_like(u), create_graph=True)[0]\n",
    "            \n",
    "            v = self.net_2(torch.cat([X, t], dim=1))\n",
    "            # v.requires_grad = True\n",
    "            v_x = torch.autograd.grad(v, X, torch.ones_like(v), create_graph=True)[0]\n",
    "            return u, u_x, v, v_x\n",
    "        \n",
    "        else:\n",
    "            X_2 = 2.0 * ( X - self.lb_2[0] ) / ( self.ub_2[0] - self.lb_2[0] ) - 1.0\n",
    "            u_2 = self.net(torch.cat([X_2, t], dim=1))\n",
    "            u_x_2 = torch.autograd.grad(u_2, X_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "            \n",
    "            v_2 = self.net_2(torch.cat([X_2, t], dim=1))\n",
    "            v_x_2 = torch.autograd.grad(v_2, X_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "        return u_2, u_x_2, v_2, v_x_2\n",
    "    \n",
    "    def f_uv(self,x, t, material):\n",
    "        if material==1:\n",
    "            u, u_x, v, v_x = self.forward(x, t, material=1)\n",
    "\n",
    "            u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0] \n",
    "            \n",
    "            u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "            \n",
    "            v_t = torch.autograd.grad(v, t, torch.ones_like(v), create_graph=True)[0]\n",
    "            # v_xx = torch.autograd.grad(v_x, x, torch.ones_like(v_x), create_graph=True)[0]\n",
    "\n",
    "            ce=2.1E-5*(u+1)\n",
    "            cl=2.5E-3\n",
    "            G=0.000026\n",
    "            k=3.15E-5\n",
    "            tp=0.1\n",
    "            delta=0.153\n",
    "            R=0.93\n",
    "            J=1.666667E-2\n",
    "            pow = x/delta+2.77*((t-2*tp)/(tp))**2\n",
    "            sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "            S= (sp/ce)*torch.exp(-pow)\n",
    "            k_ce = 1.50*(1/(u+1))\n",
    "            \n",
    "            f_u = u_t - k_ce*((u+1)/(v+1))*u_xx - (k_ce)*(u_x*(v+1)-v_x*(u+1))/((v+1)**2)*(u_x) + (G/ce)*(u-v) - S\n",
    "            f_v = v_t - (G/cl)*(u-v)\n",
    "\n",
    "            return f_u, f_v\n",
    "        \n",
    "        else:\n",
    "            x_2 = x\n",
    "            t_2 = t\n",
    "            u_2, u_x_2, v_2, v_x_2 = self.forward(x_2, t_2, material=2)\n",
    "            \n",
    "            u_t_2 = torch.autograd.grad(u_2, t_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "            u_xx_2 = torch.autograd.grad(u_x_2, x_2, torch.ones_like(u_x_2), create_graph=True)[0]\n",
    "            \n",
    "            v_t_2 = torch.autograd.grad(v_2, t_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "            # v_xx_2 = torch.autograd.grad(v_x_2, x_2, torch.ones_like(v_x_2), create_graph=True)[0]\n",
    "            \n",
    "            ce_2=5.8E-5*(u_2+1)\n",
    "            cl_2=3.3E-3\n",
    "            G_2 = 0.00042\n",
    "            k_2=9.4E-6\n",
    "            tp=0.1\n",
    "            delta=0.153\n",
    "            R=0.93\n",
    "            J=1.666667E-2\n",
    "            pow = x_2/delta+2.77*((t_2-2*tp)/(tp))**2\n",
    "            sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "            S= (sp/ce_2)*torch.exp(-pow)\n",
    "            \n",
    "            k_ce_2 = 1.62E-1*(1/(u_2+1))\n",
    "            f_u_2 = u_t_2 - k_ce_2*((u_2+1)/(v_2+1))*u_xx_2 - (k_ce_2)*(u_x_2*(v_2+1)-v_x_2*(u_2+1))/((v_2+1)**2)*(u_x_2) + (G_2/ce_2)*(u_2-v_2) - S\n",
    "            f_v_2 = v_t_2 - (G_2/cl_2)*(u_2-v_2)\n",
    "\n",
    "            return f_u_2, f_v_2\n",
    "        \n",
    "        \n",
    "\n",
    "    # def forward_1(self, X, t):\n",
    "    #     X = 2.0 * ( X - self.lb ) / ( self.ub - self.lb ) - 1.0\n",
    "    #     u = self.net_1(torch.cat([X, t], dim=1))\n",
    "    #     u_x = torch.autograd.grad(u, X, torch.ones_like(u), create_graph=True)[0]\n",
    "        \n",
    "    #     v = self.net_2(torch.cat([X, t], dim=1))\n",
    "    #     v_x = torch.autograd.grad(v, X, torch.ones_like(v), create_graph=True)[0]\n",
    "    #     return u, u_x, v, v_x   # T_e, T_e_x, T_l, T_l_x all for material 1\n",
    "    \n",
    "    # For material 2, Cr\n",
    "    # def forward_2(self, X_2, t_2):\n",
    "    #     X_2 = 2.0 * ( X_2 - self.lb_2 ) / ( self.ub_2 - self.lb_2 ) - 1.0\n",
    "    #     u_2 = self.u(torch.cat([X_2, t_2], dim=1))\n",
    "    #     u_x_2 = torch.autograd.grad(u_2, X_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "        \n",
    "    #     v_2 = self.v(torch.cat([X_2, t_2], dim=1))\n",
    "    #     v_x_2 = torch.autograd.grad(v_2, X_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "    #     return u_2, u_x_2, v_2, v_x_2\n",
    "    \n",
    "    # For the first material (Au)\n",
    "    \n",
    "    ### Change the u_xx later\n",
    "    # def f_uv_1(self, x, t):\n",
    "        # u, u_x, v, v_x = self.forward_1(x, t)\n",
    "        \n",
    "        # u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0] \n",
    "        # u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "        \n",
    "        # v_t = torch.autograd.grad(v, t, torch.ones_like(v), create_graph=True)[0]\n",
    "        # # v_xx = torch.autograd.grad(v_x, x, torch.ones_like(v_x), create_graph=True)[0]\n",
    "\n",
    "        # ce=2.1E-5*(u+1)\n",
    "        # cl=2.5E-3\n",
    "        # G=0.000026\n",
    "        # k=3.15E-5\n",
    "        # tp=0.1\n",
    "        # delta=0.153\n",
    "        # R=0.93\n",
    "        # J=1.666667E-2\n",
    "        # pow = x/delta+2.77*((t-2*tp)/(tp))**2\n",
    "        # sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "        # S= (sp/ce)*torch.math.exp(-pow)\n",
    "        # k_ce = 1.50*(1/(u+1))\n",
    "        \n",
    "        # f_u = u_t - k_ce*((u+1)/(v+1))*u_xx - (k_ce)*(u_x*(v+1)-v_x*(u+1))/((v+1)**2)*(u_x) + (G/ce)*(u-v) - S\n",
    "        # f_v = v_t - (G/cl)*(u-v)\n",
    "\n",
    "        # return f_u, f_v\n",
    "    \n",
    "    # def f_uv_2(self, x_2, t_2):\n",
    "        # u_2, u_x_2, v_2, v_x_2 = self.forward(x_2, t_2)\n",
    "        \n",
    "        # u_t_2 = torch.autograd.grad(u_2, t_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "        # u_xx_2 = torch.autograd.grad(u_x_2, x_2, torch.ones_like(u_x_2), create_graph=True)[0]\n",
    "        \n",
    "        # v_t_2 = torch.autograd.grad(v_2, t_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "        # # v_xx_2 = torch.autograd.grad(v_x_2, x_2, torch.ones_like(v_x_2), create_graph=True)[0]\n",
    "        \n",
    "        # ce_2=5.8E-5*(u_2+1)\n",
    "        # cl_2=3.3E-3\n",
    "        # G_2 = 0.00042\n",
    "        # k_2=9.4E-6\n",
    "        # tp=0.1\n",
    "        # delta=0.153\n",
    "        # R=0.93\n",
    "        # J=1.666667E-2\n",
    "        # pow = x_2/delta+2.77*((t_2-2*tp)/(tp))**2\n",
    "        # sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "        # S= (sp/ce_2)*torch.math.exp(-pow)\n",
    "        \n",
    "        # k_ce_2 = 1.62E-1*(1/(u_2+1))\n",
    "        # f_u_2 = u_t_2 - k_ce_2*((u_2+1)/(v_2+1))*u_xx_2 - (k_ce_2)*(u_x_2*(v_2+1)-v_x_2*(u_2+1))/((v_2+1)**2)*(u_x_2) + (G_2/ce_2)*(u_2-v_2) - S\n",
    "        # f_v_2 = v_t_2 - (G_2/cl_2)*(u_2-v_2)\n",
    "\n",
    "        # return f_u_2, f_v_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn( f_u, f_v, f_u_2, f_v_2, u_x_lb, u_x_2_ub, v_x_lb, v_x_2_ub, u_1_interface, u_2_interface, v_1_interface, v_2_interface, u_x_1_interface, u_x_2_interface, u_1_initial, T_e_1_initial, v_1_initial, T_l_1_initial, u_2_initial, T_e_2_initial, v_2_initial, T_l_2_initial):\n",
    "    loss = 0.0\n",
    "    k1 = 3.15E-5\n",
    "    k2 = 9.4E-6\n",
    "    \n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    # loss(1) PDE1\n",
    "    l1 = mse(f_u, torch.zeros_like(f_u))\n",
    "    \n",
    "    # loss(2) PDE1\n",
    "    l2 = mse(f_v, torch.zeros_like(f_v))\n",
    "    \n",
    "    # loss(1) PDE2\n",
    "    l3 = mse(f_u_2, torch.zeros_like(f_u_2))\n",
    "    \n",
    "    # loss(2) PDE2\n",
    "    l4 = mse(f_v_2, torch.zeros_like(f_v_2))\n",
    "    \n",
    "    #loss(1) Insulated cond 1\n",
    "    l5 = mse( u_x_lb, u_x_2_ub )\n",
    "    \n",
    "    # loss(2) Insulated cond 2\n",
    "    l6 = mse( v_x_lb, v_x_2_ub )\n",
    "    \n",
    "    # interface loss 1\n",
    "    l7 = mse( u_1_interface, u_2_interface )\n",
    "    \n",
    "    # interface loss 2\n",
    "    vec = k1*((u_1_interface+1)/(v_1_interface+1))*u_x_2_interface - k2*((u_2_interface+1)/(v_2_interface+1))*u_x_2_interface\n",
    "    \n",
    "    l8 = mse( vec, torch.zeros_like(vec) ) \n",
    "    \n",
    "    # initial condition(1) 1\n",
    "    l9 = mse( u_1_initial, T_e_1_initial )\n",
    "    \n",
    "    # initial condition(1) 2\n",
    "    l10 = mse( v_1_initial, T_l_1_initial )\n",
    "    \n",
    "    # initial condition(2) 1\n",
    "    l11 = mse( u_2_initial, T_e_2_initial )\n",
    "    \n",
    "    # initial condition(2) 2\n",
    "    l12 = mse( v_2_initial, T_l_2_initial )\n",
    "    \n",
    "    loss = l1 + l2 + l3 + l4 + l5 + l6 + l7 + l8 + l9 + l10 + l11 + l12\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_pinn(x, test_size=0.2):\n",
    "    x_train, x_test = train_test_split(x, test_size=test_size, random_state=42)\n",
    "    train_dataset = DataLoader(TensorDataset(x_train.float()), batch_size=32, shuffle=True)\n",
    "    test_dataset = DataLoader(TensorDataset(x_test.float()), batch_size=32, shuffle=False)\n",
    "    # train_dataset = TensorDataset(x_train.float())\n",
    "    # test_dataset = TensorDataset(x_test.float())\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataset():\n",
    "    \n",
    "#     lb = torch.Tensor([0.0, 0.0])\n",
    "#     ub = torch.Tensor([0.5, 1.0])\n",
    "    \n",
    "#     lb2 = torch.Tensor([0.5, 0.0])\n",
    "#     ub2 = torch.Tensor([1.0, 1.0])\n",
    "    \n",
    "#     # Au\n",
    "#     x = torch.linspace(0.0,0.5,100)\n",
    "#     t = torch.linspace(0.0,1.0,300)\n",
    "#     X, T = torch.meshgrid(x, t)\n",
    "#     X_star = torch.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "#     # u_star = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "#     # v_star = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "#     X_star.requires_grad = True\n",
    "#     # u_star.requires_grad = True\n",
    "#     # v_star.requires_grad = True\n",
    "    \n",
    "        \n",
    "#     # Cr\n",
    "#     x_2 = torch.linspace(0.5,1.0,100)\n",
    "#     t_2 = torch.linspace(0.0,1.0,300)\n",
    "#     X_2, T_2 = torch.meshgrid(x_2, t_2)\n",
    "#     X_star_2 = torch.hstack((X_2.flatten()[:, None], T_2.flatten()[:, None]))\n",
    "#     # u_star_2 = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "#     # v_star_2 = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "#     X_star_2.requires_grad = True\n",
    "#     # u_star_2.requires_grad = True\n",
    "#     # v_star_2.requires_grad = True\n",
    "    \n",
    "    \n",
    "#     train_dataloader, test_dataloader = dataloader_pinn(X_star)\n",
    "#     train_dataloader_2, test_dataloader_2 = dataloader_pinn(X_star_2)\n",
    "    \n",
    "#     # initial condition\n",
    "#     X_1_initial=X_star[X_star[:,1]==0]\n",
    "#     X_2_initial= X_star_2[X_star_2[:,1]==0]\n",
    "    \n",
    "#     # boundary condition\n",
    "#     X_1_bounds_left=X_star[X_star[:,0]==lb[0]]\n",
    "#     X_1_bounds_interface=X_star[X_star[:,0]==ub[0]]\n",
    "\n",
    "    \n",
    "#     X_2_bounds_interface=X_star_2[X_star_2[:,0]==lb2[0]]\n",
    "#     X_2_bounds_right=X_star_2[X_star_2[:,0]==ub2[1]]\n",
    "    \n",
    "#     dataset_initial = DataLoader( TensorDataset(X_1_initial,X_2_initial), batch_size=32)\n",
    "#     dataset_boundaries = DataLoader( TensorDataset( X_1_bounds_left, X_2_bounds_right), batch_size=32)\n",
    "#     dataset_interface = DataLoader( TensorDataset( X_1_bounds_interface, X_2_bounds_interface), batch_size=32)\n",
    "\n",
    "#     DL = ConcatDataset( ( train_dataloader, TensorDataset(X_1_initial,X_2_initial), TensorDataset( X_1_bounds_left, X_2_bounds_right), TensorDataset( X_1_bounds_interface, X_2_bounds_interface)  ) )\n",
    "    \n",
    "#     # loader_IC = DataLoader(train_dataset_initial, batch_size=32, shuffle=True)\n",
    "#     # loader_BC = DataLoader(train_dataset_boundaries, batch_size=32, shuffle=True)\n",
    "    \n",
    "    \n",
    "#     return (train_dataloader, train_dataloader_2), (test_dataloader, test_dataloader_2), dataset_initial, dataset_boundaries, dataset_interface, DL\n",
    "\n",
    "# tuple_train_dataloader, tuple_test_dataloader, dataloader_initial, dataloader_boundaries, dataloader_interface, DL = create_dataset()\n",
    "# zipped_train_data = zip(cycle(tuple_train_dataloader), dataloader_initial, dataloader_boundaries, dataloader_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deeponet/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset():\n",
    "    \n",
    "    lb = torch.Tensor([0.0, 0.0])\n",
    "    ub = torch.Tensor([0.5, 1.0])\n",
    "    \n",
    "    lb2 = torch.Tensor([0.5, 0.0])\n",
    "    ub2 = torch.Tensor([1.0, 1.0])\n",
    "    \n",
    "    # Au\n",
    "    x = torch.linspace(0.0,0.5,100)\n",
    "    t = torch.linspace(0.0,1.0,300)\n",
    "    X, T = torch.meshgrid(x, t)\n",
    "    X_star = torch.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "    # u_star = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "    # v_star = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "    X_star.requires_grad = True\n",
    "    # u_star.requires_grad = True\n",
    "    # v_star.requires_grad = True\n",
    "    \n",
    "        \n",
    "    # Cr\n",
    "    x_2 = torch.linspace(0.5,1.0,100)\n",
    "    t_2 = torch.linspace(0.0,1.0,300)\n",
    "    X_2, T_2 = torch.meshgrid(x_2, t_2)\n",
    "    X_star_2 = torch.hstack((X_2.flatten()[:, None], T_2.flatten()[:, None]))\n",
    "    # u_star_2 = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "    # v_star_2 = torch.linspace(0.0,0.0,100).flatten()[:,None].T.flatten()[:,None]\n",
    "    X_star_2.requires_grad = True\n",
    "    # u_star_2.requires_grad = True\n",
    "    # v_star_2.requires_grad = True\n",
    "    \n",
    "    \n",
    "    train_dataloader, test_dataloader = dataloader_pinn(X_star)\n",
    "    train_dataloader_2, test_dataloader_2 = dataloader_pinn(X_star_2)\n",
    "    \n",
    "    # initial condition\n",
    "    X_1_initial=X_star[X_star[:,1]==0]\n",
    "    X_2_initial= X_star_2[X_star_2[:,1]==0]\n",
    "    \n",
    "    # boundary condition\n",
    "    X_1_bounds_left=X_star[X_star[:,0]==lb[0]]\n",
    "    X_1_bounds_interface=X_star[X_star[:,0]==ub[0]]\n",
    "\n",
    "    \n",
    "    X_2_bounds_interface=X_star_2[X_star_2[:,0]==lb2[0]]\n",
    "    X_2_bounds_right=X_star_2[X_star_2[:,0]==ub2[1]]\n",
    "    \n",
    "    dataset_initial = DataLoader( TensorDataset(X_1_initial,X_2_initial), batch_size=32)\n",
    "    dataset_boundaries = DataLoader( TensorDataset( X_1_bounds_left, X_2_bounds_right), batch_size=32)\n",
    "    dataset_interface = DataLoader( TensorDataset( X_1_bounds_interface, X_2_bounds_interface), batch_size=32)\n",
    "\n",
    "    return (train_dataloader, train_dataloader_2), (test_dataloader, test_dataloader_2), TensorDataset(X_1_initial,X_2_initial), TensorDataset( X_1_bounds_left, X_2_bounds_right), TensorDataset( X_1_bounds_interface, X_2_bounds_interface)\n",
    "\n",
    "tuple_train_dataloader, tuple_test_dataloader, ds_initial, ds_boundaries, ds_interface = create_dataset()\n",
    "# zipped_train_data = zip(cycle(tuple_train_dataloader), ds_initial, ds_boundaries, ds_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(pinn: PINN, epochs):\n",
    "    train_losses = []\n",
    "    network = pinn.net\n",
    "    network_2 = pinn.net_2\n",
    "    network.train()\n",
    "    network_2.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam( list(network.parameters()) + list(network_2.parameters()), lr=0.0001 )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        # for tr_loader, ds_initial, ds_boundaries, ds_interface in DL:\n",
    "        for tr_loader_1, tr_loader_2, ds_initial_, ds_boundaries_, ds_interface_  in zip(tuple_train_dataloader[0], tuple_train_dataloader[1], DataLoader(ds_initial, batch_size=32), DataLoader(ds_boundaries, batch_size=32), DataLoader(ds_interface, batch_size=32)):\n",
    "        # for batch_idx, (tr_loader, ds_initial, ds_boundaries, ds_interface) in enumerate(zipped_train_data):\n",
    "            # tr_loader_1, tr_loader_2 = tr_loader\n",
    "            \n",
    "            \n",
    "            \n",
    "            # tr_loader_1, tr_loader_2 = zip_train\n",
    "            X_1_initial, X_2_initial = ds_initial_\n",
    "            X_1_bounds_interface, X_2_bounds_interface = ds_interface_\n",
    "            X_1_bounds_left, X_2_bounds_right = ds_boundaries_\n",
    "            \n",
    "            X_star = tr_loader_1[0]\n",
    "            X_star_2 = tr_loader_2[0]\n",
    "            \n",
    "            # full grid\n",
    "            ## X_star: [X_full, T_full]; X_full \\belongsto [0,0.5], T_full \\belongsto [0,1]\n",
    "            X_f = X_star[:, 0:1]\n",
    "            t_f = X_star[:, 1:2]\n",
    "            \n",
    "            ## X_star_2: [X_full, T_full]; X_full \\belongsto [0.5,1], T_full \\belongsto [0,1]\n",
    "            X_f_2 = X_star_2[:, 0:1]\n",
    "            t_f_2 = X_star_2[:, 1:2]\n",
    "            \n",
    "            # interface- left boundary\n",
    "            X_int_1 = X_1_bounds_interface[:,0:1]\n",
    "            t_int_1 = X_1_bounds_interface[:,1:2]\n",
    "            \n",
    "            X_int_2 = X_2_bounds_interface[:,0:1]\n",
    "            t_int_2 = X_2_bounds_interface[:,1:2]\n",
    "            \n",
    "            # left boundary\n",
    "            X_lb_1 = X_1_bounds_left[:,0:1]\n",
    "            t_lb_1 = X_1_bounds_left[:,1:2]\n",
    "            \n",
    "            \n",
    "            # upper/right boundary\n",
    "            X_ub_2 = X_2_bounds_right[:,0:1]\n",
    "            t_ub_2 = X_2_bounds_right[:,1:2]\n",
    "            \n",
    "            # initial condition\n",
    "            X_initial_1 = X_1_initial[:, 0:1]\n",
    "            t_initial_1 = X_1_initial[:, 1:2]\n",
    "            \n",
    "            X_initial_2 = X_2_initial[:, 0:1]\n",
    "            t_initial_2 = X_2_initial[:, 1:2]\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Over the domain   \n",
    "            # f_u, f_v = pinn.f_uv_1(X_f, t_f)\n",
    "            # f_u_2, f_v_2 = pinn.f_uv_2(X_f_2, t_f_2)\n",
    "            f_u, f_v = pinn.f_uv(X_f, t_f, material=1)\n",
    "            f_u_2, f_v_2 = pinn.f_uv(X_f_2, t_f_2, material=2)\n",
    "            \n",
    "            # left boundary conditions - 1\n",
    "            # _, u_x_lb, _, v_x_lb = pinn.forward_1(X_lb_1, t_lb_1)\n",
    "            _, u_x_lb, _, v_x_lb = pinn.forward(X_lb_1, t_lb_1, material=1)\n",
    "            \n",
    "            # right/upper boundary conditions - 2\n",
    "            # _, u_x_ub_2, _, v_x_ub_2 = pinn.forward_2(X_ub_2, t_ub_2)\n",
    "            _, u_x_ub_2, _, v_x_ub_2 = pinn.forward(X_ub_2, t_ub_2, material=2)\n",
    "            \n",
    "            # interface condition(1)\n",
    "            # u_interface_1, u_x_interface_1, v_interface_1, _ = pinn.forward_1( X_int_1, t_int_1 )\n",
    "            # u_interface_2, u_x_interface_2, v_interface_2, _ = pinn.forward_2( X_int_2, t_int_2 )\n",
    "            u_interface_1, u_x_interface_1, v_interface_1, _ = pinn.forward( X_int_1, t_int_1, material=1 )\n",
    "            u_interface_2, u_x_interface_2, v_interface_2, _ = pinn.forward( X_int_2, t_int_2, material=2)\n",
    "            \n",
    "            # initial conditions(1)\n",
    "            # u_initial_1, _, v_initial_1, _ = pinn.forward_1( X_initial_1, t_initial_1 )\n",
    "            # u_initial_2, _, v_initial_2, _ = pinn.forward_2( X_initial_2, t_initial_2 )\n",
    "            u_initial_1, _, v_initial_1, _ = pinn.forward( X_initial_1, t_initial_1, material=1 )\n",
    "            u_initial_2, _, v_initial_2, _ = pinn.forward( X_initial_2, t_initial_2, material=2 )\n",
    "            \n",
    "            ## setting up the initial condition\n",
    "            T_e_initial_1 = torch.zeros_like(u_initial_1)\n",
    "            T_e_initial_2 = torch.zeros_like(u_initial_2)\n",
    "            T_l_initial_1 = torch.zeros_like(v_initial_1)\n",
    "            T_l_initial_2 = torch.zeros_like(v_initial_2)\n",
    "            \n",
    "            loss = loss_fn( f_u, f_v, f_u_2, f_v_2, u_x_lb, u_x_ub_2, v_x_lb, v_x_ub_2, u_interface_1, u_interface_2, v_interface_1, v_interface_2, u_x_interface_1, u_x_interface_2, u_initial_1, T_e_initial_1, v_initial_1, T_l_initial_1, u_initial_2, T_e_initial_2, v_initial_2, T_l_initial_2)\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch} Loss: {epoch_loss}')\n",
    "        train_losses.append(epoch_loss / len(tr_loader_1))\n",
    "        \n",
    "    return train_losses\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 80, 80, 80, 80, 80,  1]\n",
    "bounds_1 = torch.Tensor( [ [0.0, 0.0], [0.5, 1.0] ] )\n",
    "bounds_2 = torch.Tensor( [ [0.5, 0.0], [1.0, 1.0] ] )\n",
    "pinn = PINN(layers, bounds_1 , bounds_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 33373.92022705078\n",
      "Epoch 100 Loss: 13113.009521484375\n",
      "Epoch 200 Loss: 23704.0390625\n",
      "Epoch 300 Loss: 9666.203109741211\n",
      "Epoch 400 Loss: 14339.057861328125\n",
      "Epoch 500 Loss: 7318.112854003906\n",
      "Epoch 600 Loss: 15853.283752441406\n",
      "Epoch 700 Loss: 5268.3204345703125\n",
      "Epoch 800 Loss: 8387.764038085938\n",
      "Epoch 900 Loss: 6256.1632080078125\n"
     ]
    }
   ],
   "source": [
    "train_losses = train_pinn(pinn, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pinn(pinn: PINN, optimizer, layers, tuple_test_dataloader):\n",
    "    \n",
    "    test_losses = []\n",
    "    network = pinn.net(layers)\n",
    "    network_2 = pinn.net_2(layers)\n",
    "    network.eval()\n",
    "    network_2.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for test_dl_1, test_dl_2 in tuple_test_dataloader:\n",
    "            \n",
    "            X_star = test_dl_1\n",
    "            X_star_2 = test_dl_2\n",
    "            \n",
    "            X = X_star[:,0:1]\n",
    "            t = X_star[:,1:2]\n",
    "            \n",
    "            X_2 = X_star_2[:,0:1]\n",
    "            t_2 = X_star_2[:, 1:2]\n",
    "            \n",
    "            u_1, u_x_1, v_1, v_x_1 = pinn.forward(X,t, material=1)\n",
    "            u_2, u_x_2, v_2, v_x_2 = pinn.forward(X_2, t_2, material=2)\n",
    "\n",
    "            ### TEST LOSS???\n",
    "            loss = optimizer(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "    test_loss /= len(test_dl_1)\n",
    "    # print('Test Loss: %.6f' % test_loss)\n",
    "\n",
    "    return torch.cat(all_outputs), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
