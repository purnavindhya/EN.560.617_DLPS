{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import cycle\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    '''\n",
    "    input : nodes--- list\n",
    "                form [input features, hiddenlayer1, hiddenlayer2,...., outputfeatures]\n",
    "    '''\n",
    "    def __init__(self, nodes):\n",
    "        super(NN, self).__init__()\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for node in range(len(nodes)-2):\n",
    "            self.hidden_layers.append(nn.Linear(nodes[node], nodes[node+1]))\n",
    "        self.output_layer = nn.Linear(nodes[-2] , nodes[-1])\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers, bounds_1, bounds_2 ):\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        # u: T_e(1)\n",
    "        # v: T_l(1)\n",
    "        self.net_u_1 = NN(layers)\n",
    "        self.net_v_1 = NN(layers)\n",
    "        self.net_u_2 = NN(layers)\n",
    "        self.net_v_2 = NN(layers)\n",
    "        \n",
    "        # self.net_u_1.init_weights()\n",
    "        # self.net_v_1.init_weights()\n",
    "        # self.net_u_2.init_weights()\n",
    "        # self.net_v_2.init_weights()\n",
    "        \n",
    "        # for the first material, Au\n",
    "        lb_1 = bounds_1[0]\n",
    "        ub_1 = bounds_1[1]\n",
    "        self.lb_1 = lb_1\n",
    "        self.ub_1 = ub_1\n",
    "        \n",
    "        # for the second material, Cr\n",
    "        lb_2 = bounds_2[0]\n",
    "        ub_2 = bounds_2[1]\n",
    "        self.lb_2 = lb_2\n",
    "        self.ub_2 = ub_2\n",
    "        \n",
    "        \n",
    "    def forward(self, X, t, material):\n",
    "        if material==1:\n",
    "            # X = 2.0 * ( X - self.lb_1[0] ) / ( self.ub_1[0] - self.lb_1[0] ) - 1.0\n",
    "            u = self.net_u_1(torch.cat([X, t], dim=1))\n",
    "            u_x = torch.autograd.grad(u, X, torch.ones_like(u), create_graph=True)[0]\n",
    "            \n",
    "            v = self.net_v_1(torch.cat([X, t], dim=1))\n",
    "            v_x = torch.autograd.grad(v, X, torch.ones_like(v), create_graph=True)[0]\n",
    "            return u, u_x, v, v_x\n",
    "        \n",
    "        else:\n",
    "            # X_2 = 2.0 * ( X - self.lb_2[0] ) / ( self.ub_2[0] - self.lb_2[0] ) - 1.0\n",
    "            X_2 = X\n",
    "            u_2 = self.net_u_2(torch.cat([X_2, t], dim=1))\n",
    "            u_x_2 = torch.autograd.grad(u_2, X_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "            \n",
    "            v_2 = self.net_v_2(torch.cat([X_2, t], dim=1))\n",
    "            v_x_2 = torch.autograd.grad(v_2, X_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "        return u_2, u_x_2, v_2, v_x_2\n",
    "    \n",
    "    def f_uv(self,x, t, material):\n",
    "        if material==1:\n",
    "            u, u_x, v, v_x = self.forward(x, t, material=1)\n",
    "\n",
    "            u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0] \n",
    "            \n",
    "            u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "            \n",
    "            v_t = torch.autograd.grad(v, t, torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "            ce=2.1E-5*(u+1)\n",
    "            cl=2.5E-3\n",
    "            G=0.000026\n",
    "            k=3.15E-5\n",
    "            tp=0.1\n",
    "            delta=0.153\n",
    "            R=0.93\n",
    "            J=1.666667E-2\n",
    "            pow = x/delta+2.77*((t-2*tp)/(tp))**2\n",
    "            sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "            S= (sp/ce)*torch.exp(-pow)\n",
    "            k_ce = 1.50*(1/(u+1))\n",
    "            \n",
    "            f_u = u_t - k_ce*((u+1)/(v+1))*u_xx - (k_ce)*(u_x*(v+1)-v_x*(u+1))/((v+1)**2)*(u_x) + (G/ce)*(u-v) - S\n",
    "            f_v = v_t - (G/cl)*(u-v)\n",
    "\n",
    "            return f_u, f_v\n",
    "        \n",
    "        else:\n",
    "            x_2 = x\n",
    "            t_2 = t\n",
    "            u_2, u_x_2, v_2, v_x_2 = self.forward(x_2, t_2, material=2)\n",
    "            \n",
    "            u_t_2 = torch.autograd.grad(u_2, t_2, torch.ones_like(u_2), create_graph=True)[0]\n",
    "            u_xx_2 = torch.autograd.grad(u_x_2, x_2, torch.ones_like(u_x_2), create_graph=True)[0]\n",
    "            \n",
    "            v_t_2 = torch.autograd.grad(v_2, t_2, torch.ones_like(v_2), create_graph=True)[0]\n",
    "            \n",
    "            ce_2=5.8E-5*(u_2+1)\n",
    "            cl_2=3.3E-3\n",
    "            G_2 = 0.00042\n",
    "            k_2=9.4E-6\n",
    "            tp=0.1\n",
    "            delta=0.153\n",
    "            R=0.93\n",
    "            J=1.666667E-2\n",
    "            pow = x_2/delta+2.77*((t_2-2*tp)/(tp))**2\n",
    "            sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "            S= (sp/ce_2)*torch.exp(-pow)\n",
    "            \n",
    "            k_ce_2 = 1.62E-1*(1/(u_2+1))\n",
    "            f_u_2 = u_t_2 - k_ce_2*((u_2+1)/(v_2+1))*u_xx_2 - (k_ce_2)*(u_x_2*(v_2+1)-v_x_2*(u_2+1))/((v_2+1)**2)*(u_x_2) + (G_2/ce_2)*(u_2-v_2) - S\n",
    "            f_v_2 = v_t_2 - (G_2/cl_2)*(u_2-v_2)\n",
    "\n",
    "            return f_u_2, f_v_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn( f_u, f_v, f_u_2, f_v_2, u_x_lb, u_x_2_ub, v_x_lb, v_x_2_ub, u_1_interface, u_2_interface, v_1_interface, v_2_interface, u_x_1_interface, u_x_2_interface, u_1_initial, T_e_1_initial, v_1_initial, T_l_1_initial, u_2_initial, T_e_2_initial, v_2_initial, T_l_2_initial):\n",
    "    loss = 0.0\n",
    "    k1 = 3.15E-5\n",
    "    k2 = 9.4E-6\n",
    "    \n",
    "    mse = nn.MSELoss()\n",
    "    \n",
    "    # loss(1) PDE1\n",
    "    l1 = mse(f_u, torch.zeros_like(f_u))\n",
    "    \n",
    "    # loss(2) PDE1\n",
    "    l2 = mse(f_v, torch.zeros_like(f_v))\n",
    "    \n",
    "    # loss(1) PDE2\n",
    "    l3 = mse(f_u_2, torch.zeros_like(f_u_2))\n",
    "    \n",
    "    # loss(2) PDE2\n",
    "    l4 = mse(f_v_2, torch.zeros_like(f_v_2))\n",
    "    \n",
    "    #loss(1) Insulated cond 1\n",
    "    l5 = mse( u_x_lb, u_x_2_ub )\n",
    "    \n",
    "    # loss(2) Insulated cond 2\n",
    "    l6 = mse( v_x_lb, v_x_2_ub )\n",
    "    \n",
    "    # interface loss 1\n",
    "    l7 = mse( u_1_interface, u_2_interface )\n",
    "    \n",
    "    # interface loss 2\n",
    "    vec = k1*((u_1_interface+1)/(v_1_interface+1))*u_x_1_interface - k2*((u_2_interface+1)/(v_2_interface+1))*u_x_2_interface\n",
    "    l8 = mse( vec, torch.zeros_like(vec) ) \n",
    "    \n",
    "    # initial condition(1) 1\n",
    "    l9 = mse( u_1_initial, T_e_1_initial )\n",
    "    \n",
    "    # initial condition(1) 2\n",
    "    l10 = mse( v_1_initial, T_l_1_initial )\n",
    "    \n",
    "    # initial condition(2) 1\n",
    "    l11 = mse( u_2_initial, T_e_2_initial )\n",
    "    \n",
    "    # initial condition(2) 2\n",
    "    l12 = mse( v_2_initial, T_l_2_initial )\n",
    "    \n",
    "    loss = l1 + l2 + l3 + l4 + l5 + l6 + l7 + l8 + l9 + l10 + l11 + l12\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    \n",
    "    lb = torch.Tensor([0.0, 0.0])\n",
    "    ub = torch.Tensor([0.5, 1.0])\n",
    "    \n",
    "    lb2 = torch.Tensor([0.5, 0.0])\n",
    "    ub2 = torch.Tensor([1.0, 1.0])\n",
    "    \n",
    "    # material 1\n",
    "    x = torch.linspace(0.0,0.5,100)\n",
    "    t = torch.linspace(0.0,1.0,300)\n",
    "    X, T = torch.meshgrid(x, t)\n",
    "    X_star = torch.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "    X_star.requires_grad = True\n",
    "\n",
    "    \n",
    "        \n",
    "    # Cr\n",
    "    x_2 = torch.linspace(0.5,1.0,100)\n",
    "    t_2 = torch.linspace(0.0,1.0,300)\n",
    "    X_2, T_2 = torch.meshgrid(x_2, t_2)\n",
    "    X_star_2 = torch.hstack((X_2.flatten()[:, None], T_2.flatten()[:, None]))\n",
    "    X_star_2.requires_grad = True\n",
    "\n",
    "    \n",
    "    \n",
    "    train_dataloader = DataLoader( TensorDataset(X_star), batch_size=10000, shuffle=True)\n",
    "    train_dataloader_2 = DataLoader( TensorDataset(X_star_2), batch_size=10000, shuffle=True)\n",
    "    \n",
    "    # initial condition\n",
    "    X_1_initial=X_star[X_star[:,1]==0]\n",
    "    X_2_initial= X_star_2[X_star_2[:,1]==0]\n",
    "    \n",
    "    # boundary condition\n",
    "    X_1_bounds_left=X_star[X_star[:,0]==lb[0]]\n",
    "    X_1_bounds_interface=X_star[X_star[:,0]==ub[0]]\n",
    "\n",
    "    \n",
    "    X_2_bounds_interface=X_star_2[X_star_2[:,0]==lb2[0]]\n",
    "    X_2_bounds_right=X_star_2[X_star_2[:,0]==ub2[1]]\n",
    "\n",
    "    return (train_dataloader, train_dataloader_2), (X_1_initial,X_2_initial), ( X_1_bounds_left, X_2_bounds_right), ( X_1_bounds_interface, X_2_bounds_interface), (X,T), (X_2, T_2), X_star, X_star_2\n",
    "\n",
    "tuple_train_dataloader, initial, boundaries, interface, mesh_1, mesh_2, X_star, X_star_2 = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_e_initial_1 = torch.Tensor([0.0])\n",
    "T_e_initial_2 = torch.Tensor([0.0])\n",
    "T_l_initial_1 = torch.Tensor([0.0])\n",
    "T_l_initial_2 = torch.Tensor([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(pinn: PINN, epochs):\n",
    "    train_losses = []\n",
    "    network_u_1 = pinn.net_u_1\n",
    "    network_v_1 = pinn.net_v_1\n",
    "    network_u_2 = pinn.net_u_2\n",
    "    network_v_2 = pinn.net_v_2\n",
    "    \n",
    "    network_u_1.to(device)\n",
    "    network_v_1.to(device)\n",
    "    network_u_2.to(device)\n",
    "    network_v_2.to(device)\n",
    "    \n",
    "    network_u_1.train()\n",
    "    network_v_1.train()\n",
    "    network_u_2.train()\n",
    "    network_v_2.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam( \n",
    "                                 [\n",
    "                *network_u_1.parameters(),\n",
    "                *network_v_1.parameters(),\n",
    "                *network_u_2.parameters(),\n",
    "                *network_v_2.parameters()\n",
    "                                ]\n",
    "                                 , lr=0.0001 )\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for tr_loader_1, tr_loader_2 in zip(tuple_train_dataloader[0], tuple_train_dataloader[1]):\n",
    "            \n",
    "\n",
    "            X_1_initial, X_2_initial = initial\n",
    "            X_1_bounds_interface, X_2_bounds_interface = interface\n",
    "            X_1_bounds_left, X_2_bounds_right = boundaries\n",
    "            \n",
    "            X_star = tr_loader_1[0]\n",
    "            X_star_2 = tr_loader_2[0]\n",
    "            \n",
    "            # full grid\n",
    "            ## X_star: [X_full, T_full]; X_full \\belongsto [0,0.5], T_full \\belongsto [0,1]\n",
    "            X_f = X_star[:, 0:1]\n",
    "            t_f = X_star[:, 1:2]\n",
    "            X_f = X_f.to(device)\n",
    "            t_f = t_f.to(device)\n",
    "            \n",
    "            ## X_star_2: [X_full, T_full]; X_full \\belongsto [0.5,1], T_full \\belongsto [0,1]\n",
    "            X_f_2 = X_star_2[:, 0:1]\n",
    "            t_f_2 = X_star_2[:, 1:2]\n",
    "            X_f_2 = X_f_2.to(device)\n",
    "            t_f_2 = t_f_2.to(device)\n",
    "            \n",
    "            # interface boundary\n",
    "            X_int_1 = X_1_bounds_interface[:,0:1]\n",
    "            t_int_1 = X_1_bounds_interface[:,1:2]\n",
    "            X_int_1 = X_int_1.to(device)\n",
    "            t_int_1 = t_int_1.to(device)\n",
    "            \n",
    "            X_int_2 = X_2_bounds_interface[:,0:1]\n",
    "            t_int_2 = X_2_bounds_interface[:,1:2]\n",
    "            X_int_2 = X_int_2.to(device)\n",
    "            t_int_2 = t_int_2.to(device)\n",
    "            \n",
    "            # left boundary\n",
    "            X_lb_1 = X_1_bounds_left[:,0:1]\n",
    "            t_lb_1 = X_1_bounds_left[:,1:2]\n",
    "            X_lb_1 = X_lb_1.to(device)\n",
    "            t_lb_1 = t_lb_1.to(device)\n",
    "            \n",
    "            \n",
    "            # upper/right boundary\n",
    "            X_ub_2 = X_2_bounds_right[:,0:1]\n",
    "            t_ub_2 = X_2_bounds_right[:,1:2]\n",
    "            X_ub_2 = X_ub_2.to(device)\n",
    "            t_ub_2 = t_ub_2.to(device)\n",
    "            \n",
    "            # initial condition\n",
    "            X_initial_1 = X_1_initial[:, 0:1]\n",
    "            t_initial_1 = X_1_initial[:, 1:2]\n",
    "            X_initial_1 = X_initial_1.to(device)\n",
    "            t_initial_1 = t_initial_1.to(device)\n",
    "            \n",
    "            X_initial_2 = X_2_initial[:, 0:1]\n",
    "            t_initial_2 = X_2_initial[:, 1:2]\n",
    "            X_initial_2 = X_initial_2.to(device)\n",
    "            t_initial_2 = t_initial_2.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Over the domain   \n",
    "            f_u, f_v = pinn.f_uv(X_f, t_f, material=1)\n",
    "            f_u_2, f_v_2 = pinn.f_uv(X_f_2, t_f_2, material=2)\n",
    "            \n",
    "            # left boundary conditions - 1\n",
    "            _, u_x_lb, _, v_x_lb = pinn.forward(X_lb_1, t_lb_1, material=1)\n",
    "            \n",
    "            # right/upper boundary conditions - 2\n",
    "            _, u_x_ub_2, _, v_x_ub_2 = pinn.forward(X_ub_2, t_ub_2, material=2)\n",
    "            \n",
    "            # interface condition(1)\n",
    "            u_interface_1, u_x_interface_1, v_interface_1, _ = pinn.forward( X_int_1, t_int_1, material=1 )\n",
    "            u_interface_2, u_x_interface_2, v_interface_2, _ = pinn.forward( X_int_2, t_int_2, material=2)\n",
    "            \n",
    "            # initial conditions(1)\n",
    "            u_initial_1, _, v_initial_1, _ = pinn.forward( X_initial_1, t_initial_1, material=1 )\n",
    "            u_initial_2, _, v_initial_2, _ = pinn.forward( X_initial_2, t_initial_2, material=2 )\n",
    "            \n",
    "            loss = loss_fn( f_u, f_v, f_u_2, f_v_2, u_x_lb, u_x_ub_2, v_x_lb, v_x_ub_2, u_interface_1, u_interface_2, v_interface_1, v_interface_2, u_x_interface_1, u_x_interface_2, u_initial_1, T_e_initial_1, v_initial_1, T_l_initial_1, u_initial_2, T_e_initial_2, v_initial_2, T_l_initial_2)\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "        scheduler.step()\n",
    "        train_losses.append(epoch_loss / len(tr_loader_1[0]))\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch} Loss: {epoch_loss / len(tr_loader_1[0])}')\n",
    "        \n",
    "    return train_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pinn(pinn: PINN, X_star, t_star, X_star_2, t_star_2):\n",
    "    pinn.net_u_1.eval()\n",
    "    pinn.net_v_1.eval()\n",
    "    pinn.net_u_2.eval()\n",
    "    pinn.net_v_2.eval()\n",
    "    with torch.no_grad():\n",
    "        u_pred_1, _, v_pred_1, _ = pinn.forward(X_star, t_star, material=1)\n",
    "        u_pred_2, _, v_pred_2, _ = pinn.forward(X_star_2, t_star_2, material=2)\n",
    "    return u_pred_1, v_pred_1, u_pred_2, v_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 80, 80, 80, 80, 80,  1]\n",
    "bounds_1 = torch.Tensor( [ [0.0, 0.0], [0.5, 1.0] ] )\n",
    "bounds_2 = torch.Tensor( [ [0.5, 0.0], [1.0, 1.0] ] )\n",
    "pinn = PINN(layers, bounds_1 , bounds_2 )\n",
    "train_losses = train_pinn(pinn, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred_1, v_pred_1, u_pred_2, v_pred_2 = test_pinn(pinn, X_star= X_star[:,0:1],  t_star= X_star[:,1:2], X_star_2= X_star_2[:,0:1], t_star_2= X_star_2[:,1:2] )\n",
    "U_pred_1 = griddata( X_star[:,0:1], u_pred_1.flatten(), mesh_1, method='cubic')\n",
    "V_pred_1 = griddata( X_star[:,0:1], v_pred_1.flatten(), mesh_2, method='cubic')\n",
    "\n",
    "U_pred_2 = griddata( X_star_2[:,0:1], u_pred_2.flatten(), mesh_1, method='cubic')\n",
    "V_pred_2 = griddata( X_star_2[:,0:1], v_pred_2.flatten(), mesh_2, method='cubic')\n",
    "\n",
    "U_pred_1 = U_pred_1*300 + 300\n",
    "V_pred_1 = V_pred_1*300 + 300\n",
    "U_pred_2 = U_pred_2*300 + 300\n",
    "V_pred_2 = V_pred_2*300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "X, T = mesh_1\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, U_pred_1, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$U_pred_1$')\n",
    "ax.set_title('surface')\n",
    "plt.savefig('surf.pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "X, T = mesh_1\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, U_pred_2, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$U_pred_2$')\n",
    "ax.set_title('surface')\n",
    "plt.savefig('surf.pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "X, T = mesh_1\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, V_pred_1, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$V_pred_1$')\n",
    "ax.set_title('surface')\n",
    "plt.savefig('surf.pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "X, T = mesh_1\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, V_pred_2, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$V_pred_2$')\n",
    "ax.set_title('surface');\n",
    "plt.savefig('surf.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTTM(nn.Module):\n",
    "    def __init__(self, layers, bounds):\n",
    "        super(NTTM, self).__init__()\n",
    "        self.net_T1 = NN(layers)\n",
    "        self.net_T2 = NN(layers)\n",
    "        self.net_q = NN(layers)\n",
    "        self.net_T1.init_weights()\n",
    "        self.net_T2.init_weights()\n",
    "        self.net_q.init_weights()\n",
    "        \n",
    "        self.lb = bounds[0]\n",
    "        self.ub = bounds[1]\n",
    "        \n",
    "    def forward(self, X, t, variable):\n",
    "        if variable == 'T1':\n",
    "            X = 2.0 * ( X - self.lb ) / ( self.ub - self.lb ) - 1.0\n",
    "            T1 = self.net_T1(torch.cat([X, t], dim=1))\n",
    "            T1_x = torch.autograd.grad(T1, X, torch.ones_like(T1), create_graph=True)[0]\n",
    "            return T1, T1_x\n",
    "        elif variable == 'T2':\n",
    "            X = 2.0 * ( X - self.lb ) / ( self.ub- self.lb ) - 1.0\n",
    "            T2 = self.net_T2(torch.cat([X, t], dim=1))\n",
    "            T2_x = torch.autograd.grad(T2, X, torch.ones_like(T2), create_graph=True)[0]\n",
    "            return T2, T2_x\n",
    "        else:\n",
    "            X = 2.0 * ( X - self.lb) / ( self.ub - self.lb ) - 1.0\n",
    "            q = self.net_q(torch.cat([X, t], dim=1))\n",
    "            q_x = torch.autograd.grad(q, X, torch.ones_like(q), create_graph=True)[0]\n",
    "            q_xx = torch.autograd.grad(q_x, X, torch.ones_like(q_x), create_graph=True)[0]\n",
    "            return q, q_xx\n",
    "        \n",
    "    def f_quv(self, X, t):\n",
    "        q, q_xx = self.forward(X, t, variable='q')\n",
    "        T1, T1_x = self.forward(X, t, variable='T1')\n",
    "        T2, T2_x = self.forward(X, t, variable='T2')\n",
    "            \n",
    "        q_t = torch.autograd.grad(q, t, torch.ones_like(q), create_graph=True)[0]\n",
    "        q_tx = torch.autograd.grad(q_t, X, torch.ones_like(q_t), create_graph=True)[0]\n",
    "        q_xxx = torch.autograd.grad(q_xx, X, torch.ones_like(q_xx), create_graph=True)[0]\n",
    "            \n",
    "        T1_t = torch.autograd.grad(T1, t, torch.ones_like(T1), create_graph=True)[0]\n",
    "        T1_xx = torch.autograd.grad(T1_x, X, torch.ones_like(T1_x), create_graph=True)[0]\n",
    "            \n",
    "        T2_t = torch.autograd.grad(T2, t, torch.ones_like(T2), create_graph=True)[0]\n",
    "            \n",
    "        ce=2.1E-5*(T1+1)\n",
    "        cl=2.5E-3\n",
    "        G=0.0000182\n",
    "        k=0.00006615\n",
    "        beta = 0.333333333333333\n",
    "        k_ce = beta*k/ce\n",
    "        tp= 0.142857142857143\n",
    "        delta= 0.153\n",
    "        R=0.93\n",
    "        J=0.000446666666666667\n",
    "        pow = X/delta+2.77*((t-2*tp)/(tp))**2\n",
    "        sp = (0.94)*((1-R)/(tp*delta))*J\n",
    "        S= (sp/ce)*torch.exp(-pow)\n",
    "        tau1 = 0.039\n",
    "        l_e = 0.377\n",
    "        new_cons = beta*l_e**2\n",
    "        new_bt = beta*tau1\n",
    "        G_new = G/ce\n",
    "        G_new1 = G/cl\n",
    "        tau = 0.039\n",
    "        tau_inv = 1.0/tau\n",
    "        k_tau = k/tau\n",
    "        le_tau = l_e**2/tau\n",
    "            \n",
    "        f_q = q_t + tau_inv*q +  (k_tau)*T1_x  - (le_tau)**2*q_xx \n",
    "        f_T1 = T1_t - (k_ce*((T1+1)/(T2+1))*T1_xx + (k_ce)*(T1_x*(T2+1)-T2_x*(T1+1))/((T2+1)**2)*(T1_x)) + new_cons*q_xxx - new_bt*q_tx  + G_new*(T1-T2) - S\n",
    "        f_T2 = T2_t - G_new1*(T1-T2)\n",
    "\n",
    "        return f_q, f_T1, f_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE THIS LATER\n",
    "T1_initial = torch.Tensor([0.0])\n",
    "T2_initial = torch.Tensor([0.0])\n",
    "q_initial = torch.Tensor([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_nttm(T1_initial_pred, T2_initial_pred, q_initial_pred, q_lb_pred, q_ub_pred, T1_lb_pred, T2_lb_pred, T1_x_lb_pred, T1_ub_pred, T2_ub_pred, T1_x_ub_pred, q_xx_lb_pred, q_xx_ub_pred, f_T1_pred, f_T2_pred, f_q_pred):\n",
    "    k=0.00006615\n",
    "    le = 0.377\n",
    "    mse = nn.MSELoss()\n",
    "    loss = 0.0\n",
    "    \n",
    "    # initial condition 1\n",
    "    l1 = mse( T1_initial, T1_initial_pred )\n",
    "    \n",
    "    # initial condition 2\n",
    "    l2 = mse( T2_initial, T2_initial_pred )\n",
    "    \n",
    "    # initial condition 3\n",
    "    l3 = mse( q_initial, q_initial_pred )\n",
    "    \n",
    "    # continuity condition - on q\n",
    "    l4 = mse( q_lb_pred, q_ub_pred )\n",
    "    \n",
    "    # continuity condition - on q_xx\n",
    "    vec_lb = k * (T1_lb_pred + 1) / (T2_lb_pred + 1) * T1_x_lb_pred - (le**2) * q_xx_lb_pred\n",
    "    vec_ub =  k * (T1_ub_pred + 1) / (T2_ub_pred + 1) * T1_x_ub_pred - (le**2) * q_xx_ub_pred\n",
    "    l5 = mse( vec_lb, vec_ub )\n",
    "    \n",
    "    # PDE 1\n",
    "    l6 = mse( f_T1_pred, torch.zeros_like(f_T1_pred) )\n",
    "    \n",
    "    # PDE 2\n",
    "    l7 = mse( f_T2_pred, torch.zeros_like(f_T2_pred) )\n",
    "    \n",
    "    # PDE 3\n",
    "    l8 = mse( f_q_pred, torch.zeros_like(f_q_pred) )\n",
    "    \n",
    "    # experimental loss\n",
    "    l9 = mse(  )\n",
    "    \n",
    "    \n",
    "    loss = l1 + l2 + l3 + l4 + l5 + l6 + l7 + l8\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nttm():\n",
    "    \n",
    "    lb = torch.Tensor([0.0, 0.0])\n",
    "    ub = torch.Tensor([1.0, 1.0])\n",
    "    \n",
    "    # material 1\n",
    "    x = torch.linspace(0.0,1.0,900)\n",
    "    t = torch.linspace(0.0,1.0,500)\n",
    "    X, T = torch.meshgrid(x, t)\n",
    "    X_star = torch.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "    X_star.requires_grad = True\n",
    "\n",
    "    train_dataloader = DataLoader( TensorDataset(X_star), batch_size=10000, shuffle=True)\n",
    "    \n",
    "    # initial condition\n",
    "    X_initial=X_star[X_star[:,1]==0]\n",
    "\n",
    "    \n",
    "    # boundary condition\n",
    "    X_bounds_left=X_star[X_star[:,0]==lb[0]]\n",
    "    X_bounds_right=X_star[X_star[:,0]==ub[0]]\n",
    "\n",
    "\n",
    "    return train_dataloader, X_initial, X_bounds_left, X_bounds_right, (X,T), X_star\n",
    "\n",
    "train_dataloader, initial, left, right, mesh_nttm, X_star_nttm = create_dataset_nttm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nttm(nttm: NTTM,train_dataloader, initial, left, right, epochs):\n",
    "    train_losses = []\n",
    "    network_T1 = nttm.net_T1\n",
    "    network_T2 = nttm.net_T2\n",
    "    network_q = nttm.net_q\n",
    "    \n",
    "    network_T1.to(device)\n",
    "    network_T2.to(device)\n",
    "    network_q.to(device)\n",
    "\n",
    "    network_T1.train()\n",
    "    network_T2.train()\n",
    "    network_q.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam( \n",
    "                                 [\n",
    "                *network_T1.parameters(),\n",
    "                *network_T2.parameters(),\n",
    "                *network_q.parameters()\n",
    "                                ]\n",
    "                                 , lr=0.0001,  betas=(0.99, 0.999) )\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for tr_loader in train_dataloader:\n",
    "            \n",
    "\n",
    "            X_initial = initial\n",
    "            X_bounds_left = left\n",
    "            X_bounds_right = right\n",
    "            X_star = tr_loader[0]\n",
    "            \n",
    "            # full grid\n",
    "            ## X_star: [X_full, T_full]; X_full \\belongsto [0,0.5], T_full \\belongsto [0,1]\n",
    "            X_f = X_star[:, 0:1]\n",
    "            t_f = X_star[:, 1:2]\n",
    "            X_f = X_f.to(device)\n",
    "            t_f = t_f.to(device)\n",
    "\n",
    "            # left boundary\n",
    "            X_lb = X_bounds_left[:,0:1]\n",
    "            t_lb = X_bounds_left[:,1:2]\n",
    "            X_lb = X_lb.to(device)\n",
    "            t_lb = t_lb.to(device)\n",
    "               \n",
    "            # upper/right boundary\n",
    "            X_ub = X_bounds_right[:,0:1]\n",
    "            t_ub = X_bounds_right[:,1:2]\n",
    "            X_ub = X_ub.to(device)\n",
    "            t_ub = t_ub.to(device)\n",
    "            \n",
    "            # initial condition\n",
    "            X_init = X_initial[:, 0:1]\n",
    "            t_init = X_initial[:, 1:2]\n",
    "            X_init = X_init.to(device)\n",
    "            t_init = t_init.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # initial conditions(1)\n",
    "            T1_initial_pred, _ = nttm.forward( X_init, t_init, variable='T1' )\n",
    "            T2_initial_pred, _ = nttm.forward( X_init, t_init, variable='T2' )\n",
    "            q_initial_pred, _ = nttm.forward( X_init, t_init, variable='q' )\n",
    "            \n",
    "            # left boundary\n",
    "            q_lb_pred, q_xx_lb_pred = nttm.forward(X_lb, t_lb, variable='q')\n",
    "            q_ub_pred, q_xx_ub_pred = nttm.forward(X_ub, t_ub, variable='q')\n",
    "            \n",
    "            T1_lb_pred, T1_x_lb_pred = nttm.forward(X_lb, t_lb, variable='T1')\n",
    "            T1_ub_pred, T1_x_ub_pred = nttm.forward(X_ub, t_ub, variable='T1')\n",
    "            \n",
    "            T2_lb_pred, _ = nttm.forward(X_lb, t_lb, variable='T2')\n",
    "            T2_ub_pred, _ = nttm.forward(X_ub, t_ub, variable='T2')\n",
    "            \n",
    "            # Over the domain   \n",
    "            f_q_pred, f_T1_pred, f_T2_pred = nttm.f_quv(X_f, t_f) \n",
    "            \n",
    "            loss = loss_nttm( T1_initial_pred, T2_initial_pred, q_initial_pred, q_lb_pred, q_ub_pred, T1_lb_pred, T2_lb_pred, T1_x_lb_pred, T1_ub_pred, T2_ub_pred, T1_x_ub_pred, q_xx_lb_pred, q_xx_ub_pred, f_T1_pred, f_T2_pred, f_q_pred )\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "        scheduler.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch} Loss: {epoch_loss}')\n",
    "        train_losses.append(epoch_loss / len(tr_loader))\n",
    "        \n",
    "    return train_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nttm(nttm: NTTM, X_star, t_star, X_star_2, t_star_2):\n",
    "    pinn.net_T1.eval()\n",
    "    pinn.net_T2.eval()\n",
    "    pinn.net.eval()\n",
    "    pinn.net_v_2.eval()\n",
    "    with torch.no_grad():\n",
    "        T1_pred, _ = nttm.forward(X_star, t_star, variable='T1')\n",
    "        T2_pred, _ = nttm.forward(X_star_2, t_star_2, variable='T2')\n",
    "        q_pred, _ = nttm.forward(X_star, t_star, variable='q')\n",
    "    return T1_pred, T2_pred, q_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nttm = NTTM(bounds=torch.Tensor( [0.0, 1.0] ), layers=[2, 100, 100, 100, 100, 100, 100, 100, 1])\n",
    "tr_losses = train_nttm(nttm, train_dataloader, initial, left, right, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m T1_pred, T2_pred, q_pred \u001b[38;5;241m=\u001b[39m test_pinn(pinn, X_star\u001b[38;5;241m=\u001b[39m X_star[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m],  t_star\u001b[38;5;241m=\u001b[39m X_star[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m], X_star_2\u001b[38;5;241m=\u001b[39m X_star_2[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], t_star_2\u001b[38;5;241m=\u001b[39m X_star_2[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] )\n\u001b[1;32m      2\u001b[0m T1_pred \u001b[38;5;241m=\u001b[39m griddata( X_star_n[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], u_pred_1\u001b[38;5;241m.\u001b[39mflatten(), mesh_nttm, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m T2_pred \u001b[38;5;241m=\u001b[39m griddata( X_star_2[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], u_pred_2\u001b[38;5;241m.\u001b[39mflatten(), mesh_1, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "T1_pred, T2_pred, q_pred = test_pinn(pinn, X_star= X_star[:,0:1],  t_star= X_star[:,1:2], X_star_2= X_star_2[:,0:1], t_star_2= X_star_2[:,1:2] )\n",
    "T1_pred = griddata( X_star_nttm[:,0:1], u_pred_1.flatten(), mesh_nttm, method='cubic')\n",
    "T2_pred = griddata( X_star_nttm[:,0:1], u_pred_2.flatten(), mesh_1, method='cubic')\n",
    "q_pred = griddata( X_star_nttm[:,0:1], q_pred.flatten(), mesh_1, method='cubic')\n",
    "\n",
    "T1_pred = T1_pred*300 + 300\n",
    "T2_pred = T2_pred*300 + 300\n",
    "q_pred = U_pred_2*300 + 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "X, T = mesh_nttm\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, T1_pred, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$T1_pred$')\n",
    "ax.set_title('surface')\n",
    "plt.savefig('surf.pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "X, T = mesh_nttm\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, T, T2_pred, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('$x_u$')\n",
    "ax.set_ylabel('$t$')\n",
    "ax.set_zlabel('$T2_pred$')\n",
    "ax.set_title('surface')\n",
    "plt.savefig('surf.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
